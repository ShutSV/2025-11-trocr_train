import os
import random
import torch
import pandas as pd
import albumentations as A
from PIL import Image
from pathlib import Path
from datetime import datetime
from torch.utils.data import Dataset

from transformers import (
    TrOCRProcessor,
    VisionEncoderDecoderModel,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    default_data_collator,
    TrainerCallback,
)
from transformers.trainer_utils import get_last_checkpoint
import evaluate
import numpy as np
import logging
import zipfile
import io
from collections import OrderedDict

from src.utils.start_tensorboard import start_tensorboard
from src.utils.settings import settings_train


logging.basicConfig(level=logging.INFO)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# –ø—É—Ç–∏
TIMESTAMP = datetime.now().strftime('%Y-%m-%d_%H-%M')
OUTPUT_DIR = Path(rf"D:\DOC\2025-11-trocr_train\output\{TIMESTAMP}")
MODEL_CHECKPOINT = "microsoft/trocr-small-handwritten"
VALIDATION_SPLIT_SIZE = 0.05
RANDOM_SEED = 42

train_csv_path = Path(rf"d:\datasets\rus\datasets\train.csv") # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É train –¥–∞—Ç–∞—Å–µ—Ç–∞
val_csv_path = Path(rf"d:\datasets\rus\datasets\val.csv") # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É val –¥–∞—Ç–∞—Å–µ—Ç–∞
images_dir_path = Path(rf"{settings_train.dataset_path}\images")  # –ò—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
LOG_DIR = Path(rf"{OUTPUT_DIR}\logs")



# --- –ó–∞–ø—É—Å–∫ TensorBoard –≤ Internet ---
start_tensorboard()  # –∫–∞–∫ –≤–∞—Ä–∏–∞–Ω—Ç:  start_cloudflare_tunnel()

# --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–π–ø–ª–∞–π–Ω –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π --- –≠—Ç–æ —Å–∏–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
train_transforms = A.Compose([
    A.Rotate(limit=5, p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),
    A.Affine(translate_percent=0.0625, scale=0.1, rotate=5, p=0.5),
    A.Blur(blur_limit=3, p=0.2),
])


# --- –ö–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞ ---
class CyrillicHandwrittenDataset(Dataset):
    def __init__(self, df, processor, root_dir, transforms=None, max_target_length=128):
        self.df = df
        self.processor = processor
        self.root_dir = root_dir
        self.transforms = transforms
        self.max_target_length = max_target_length

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        file_name = row['image_path']
        text = row['text']
        image_path = self.root_dir / file_name
        try:
            image = Image.open(image_path).convert("RGB")
        except FileNotFoundError:
            logging.warning(f"–§–∞–π–ª {image_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        if self.transforms:  # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            image_np = self.transforms(image=np.array(image))['image']
            image = Image.fromarray(image_np)
        pixel_values = self.processor(images=image, return_tensors="pt").pixel_values  # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º
        labels = self.processor.tokenizer(  # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º
            text,
            padding="max_length",
            max_length=self.max_target_length,
            truncation=True,
        ).input_ids
        # –î–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∑–∞–º–µ–Ω—è–µ–º padding-—Ç–æ–∫–µ–Ω—ã –Ω–∞ -100
        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]
        return {"pixel_values": pixel_values.squeeze(), "labels": torch.tensor(labels)}


print(f"\n–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ '{MODEL_CHECKPOINT}'...")
processor = TrOCRProcessor.from_pretrained(MODEL_CHECKPOINT)  # --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ ---
model = VisionEncoderDecoderModel.from_pretrained(MODEL_CHECKPOINT)

model.config.decoder_start_token_id = processor.tokenizer.cls_token_id  # --- –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ --- –≠—Ç–æ –ö–õ–Æ–ß–ï–í–û–ô —à–∞–≥ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ –Ω–æ–≤–æ–º —è–∑—ã–∫–µ!
model.config.pad_token_id = processor.tokenizer.pad_token_id
model.config.vocab_size = model.config.decoder.vocab_size

model.config.decoder.dropout = 0.3  # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
model.config.decoder.attention_dropout = 0.3
# model.config.encoder.dropout = 0.1

model = model.to(device)
print("\n‚úÖ –ú–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω—ã.")

train_df = pd.read_csv(train_csv_path)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ì–û–¢–û–í–´–ô DataFrame –¥–ª—è train Dataset
eval_df = pd.read_csv(val_csv_path)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ì–û–¢–û–í–´–ô DataFrame –¥–ª—è val Dataset
train_dataset = CyrillicHandwrittenDataset(df=train_df, processor=processor, root_dir=images_dir_path, transforms=train_transforms)  # --- –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---
eval_dataset = CyrillicHandwrittenDataset(df=eval_df, processor=processor, root_dir=images_dir_path) # –í–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
print(f"\n–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –û–±—É—á–µ–Ω–∏–µ: {len(train_dataset)}, –í–∞–ª–∏–¥–∞—Ü–∏—è: {len(eval_dataset)}")
print("‚úÖ Dataset –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.")

cer_metric = evaluate.load("cer")  # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç—Ä–∏–∫–∏ CER ---

def compute_metrics(pred):
    labels_ids = pred.label_ids
    pred_ids = pred.predictions
    pred_ids[pred_ids == -100] = processor.tokenizer.pad_token_id  # –ó–∞–º–µ–Ω—è–µ–º -100 –Ω–∞ pad_token_id –ø–µ—Ä–µ–¥ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id
    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)  # –î–µ–∫–æ–¥–∏—Ä—É–µ–º
    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)
    cer = cer_metric.compute(predictions=pred_str, references=label_str)
    return {"cer": cer}


print("\n‚úÖ –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –≥–æ—Ç–æ–≤–∞.")


def main(*args, **kwargs):
    training_args = Seq2SeqTrainingArguments(
        output_dir=str(OUTPUT_DIR),
        predict_with_generate=True,
        per_device_train_batch_size=64,  # 64 –¥–ª—è RTX4000ada, 48 –¥–ª—è T4 –∏ L4, 96 –¥–ª—è –ê100 (VRAM 26 –∏–∑ 40)
        per_device_eval_batch_size=128,  # 96 –¥–ª—è RTX4000ada
        fp16=True,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è

        # --- –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
        logging_dir=str(LOG_DIR),
        logging_strategy="steps",
        logging_steps=100,  # –ß–∞—Å—Ç–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–ª–∞–≤–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
        eval_strategy="steps",
        eval_steps=500,    # –ß–∞—Å—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        save_strategy="steps",
        save_steps=500,
        save_total_limit=3,
        report_to=["tensorboard"],

        # --- –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã ---
        num_train_epochs=10,
        learning_rate=1e-6,
        weight_decay=0.01,
        warmup_ratio=0.1,
        lr_scheduler_type="linear",

        # --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é ---
        load_best_model_at_end=True,
        metric_for_best_model="cer",
        greater_is_better=False,

        # --- –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
        logging_first_step=True,  # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π —à–∞–≥
        logging_nan_inf_filter=False,  # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è
        eval_accumulation_steps=5,  # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ü–µ–Ω–∫–∏
        dataloader_pin_memory=torch.cuda.is_available(),  # –£—Å–∫–æ—Ä–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        dataloader_num_workers=8,    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
    )

    class EnhancedValidationCallback(TrainerCallback):
        def __init__(self,
                     checkpoint_dir,
                     processor,
                     log_every=100,
                     num_samples=5,
                     early_stopping_patience=3):
            """
            callback –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

            :param checkpoint_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
            :param processor: –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
            :param log_every: –ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–≤ —à–∞–≥–∞—Ö)
            :param num_samples: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            :param early_stopping_patience: –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            """
            self.checkpoint_dir = Path(checkpoint_dir)
            self.processor = processor
            self.log_every = log_every
            self.num_samples = num_samples
            self.early_stopping_patience = early_stopping_patience
            self.best_cer = float('inf')
            self.epochs_no_improve = 0
            self.writer = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ

        def init_writer(self, logs):
            """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SummaryWriter"""
            if self.writer is None and 'tensorboard' in logs:
                self.writer = logs['tensorboard']
                print(f"üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ª–æ–≥–≥–µ—Ä TensorBoard")

        def on_evaluate(self, args, state, control, **kwargs):
            """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
            metrics = kwargs.get('metrics', {})
            global_step = state.global_step

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ –Ω–∞—à —à–∞–≥ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            if global_step % self.log_every != 0:
                return

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
            self.init_writer(kwargs.get('logs', {}))

            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            cer = metrics.get('eval_cer', float('inf'))
            predictions = metrics.get('eval_predictions', [])
            labels = metrics.get('eval_labels', [])

            # –õ–æ–≥–∏—Ä—É–µ–º CER
            if self.writer:
                self.writer.add_scalar("Val/cer", cer, global_step)

            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            if len(predictions) > 0 and self.writer:
                n_samples = min(self.num_samples, len(predictions))
                indices = random.sample(range(len(predictions)), n_samples)

                for i, idx in enumerate(indices):
                    pred_text = self.processor.decode(predictions[idx], skip_special_tokens=True)
                    true_text = self.processor.decode(labels[idx], skip_special_tokens=True)

                    if self.writer:
                        self.writer.add_text(
                            f"Val/sample_{i}",
                            f"True: {true_text}\nPred: {pred_text}",
                            global_step
                        )

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if cer < self.best_cer:
                self.best_cer = cer
                self.epochs_no_improve = 0

                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                best_model_dir = self.checkpoint_dir / "best_cer_model"
                best_model_dir.mkdir(parents=True, exist_ok=True)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
                kwargs['model'].save_pretrained(best_model_dir)
                self.processor.save_pretrained(best_model_dir)

                if args.local_rank in [-1, 0]:  # –¢–æ–ª—å–∫–æ –¥–ª—è –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
                    print(f"üéØ –ù–æ–≤—ã–π –ª—É—á—à–∏–π CER: {cer:.4f}. –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {best_model_dir}")
            else:
                self.epochs_no_improve += 1
                if self.epochs_no_improve >= self.early_stopping_patience:
                    print(f"‚ö†Ô∏è CER –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è {self.epochs_no_improve} —ç–ø–æ—Ö –ø–æ–¥—Ä—è–¥")

            # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
            if args.local_rank in [-1, 0]:
                print(f"Validation {datetime.now().strftime('%Y-%m-%d_%H-%M')} @ step {global_step} - CER: {cer:.4f} | Best CER: {self.best_cer:.4f}")

        def on_train_end(self, args, state, control, **kwargs):
            """–ó–∞–∫—Ä—ã–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
            if self.writer:
                self.writer.close()
                print("‚úÖ –õ–æ–≥–≥–µ—Ä TensorBoard –∑–∞–∫—Ä—ã—Ç")

    callback = EnhancedValidationCallback(
        checkpoint_dir=OUTPUT_DIR,
        processor=processor,
        log_every=200,  # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ 200 —à–∞–≥–æ–≤
        num_samples=5,  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å 5 –ø—Ä–∏–º–µ—Ä–æ–≤
        early_stopping_patience=5  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –ø–æ—Å–ª–µ 5 —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏–π
    )

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Trainer ---
    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        compute_metrics=compute_metrics,
        processing_class=processor,
        callbacks=[callback],
        data_collator=default_data_collator,
    )

    resume_training = bool(get_last_checkpoint(OUTPUT_DIR))
    trainer.train(resume_from_checkpoint=resume_training)

    # --- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ---
    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! {datetime.now().strftime('%Y-%m-%d_%H-%M')} –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å...")
    trainer.save_model(str(OUTPUT_DIR / "best_model"))
    processor.save_pretrained(str(OUTPUT_DIR / "best_model"))
    print(f"üéâ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {OUTPUT_DIR / 'best_model'}")


if __name__ == "__main__":
    # --- –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è ---
    print(f"\nüöÄ –ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï! {datetime.now().strftime('%Y-%m-%d_%H-%M')}")
    print(f"–õ–æ–≥–∏ TensorBoard –±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –≤: {LOG_DIR}")
    print("–î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: tensorboard --logdir=—É–∫–∞–∑–∞–Ω–Ω—ã–π_–≤—ã—à–µ_–ø—É—Ç—å")
    main()
