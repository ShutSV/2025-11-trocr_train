import logging
import io
from PIL import Image
from kraken import binarization, pageseg
import torch
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from models import OCRLine, OCRResponse


logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%H:%M:%S', level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö—ç—à –¥–ª—è –º–æ–¥–µ–ª–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
_model_cache = {}


def get_cached_model(model_path: str, device: str):
    """–ü–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –∫—ç—à–∞ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—É—é"""
    cache_key = f"{model_path}_{device}"

    if cache_key not in _model_cache:
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_path} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {device}")
        processor = TrOCRProcessor.from_pretrained(model_path, use_fast=False)
        model = VisionEncoderDecoderModel.from_pretrained(model_path)
        model.to(device)
        model.eval()
        _model_cache[cache_key] = (processor, model)
        logger.info(f"–ú–æ–¥–µ–ª—å {model_path} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –∫—ç—à")

    return _model_cache[cache_key]


async def ocr_image(file, model_path: str, device: str):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é
    processor, model = get_cached_model(model_path, device)

    contents = await file.read()
    image = Image.open(io.BytesIO(contents)).convert('RGB')
    logger.info(f"–ù–∞—á–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ {file.filename}")

    # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è Kraken
    gray_image = image.convert('L')
    binary_image = binarization.nlbin(gray_image)
    segmentation_result = pageseg.segment(binary_image)
    qnty_lines = len(segmentation_result.lines)
    logger.info(f"–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è {file.filename} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫: {qnty_lines}")

    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ TrOCR
    ocr_lines = []
    for i, line in enumerate(segmentation_result.lines):
        x1, y1, x2, y2 = line.bbox
        line_image = image.crop((x1, y1, x2, y2))
        pixel_values = processor(images=line_image, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(device)

        with torch.no_grad():
            generated_ids = model.generate(pixel_values)

        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

        ocr_line = OCRLine(
            line_number=i + 1,
            bbox=[x1, y1, x2, y2],
            text=generated_text
        )
        ocr_lines.append(ocr_line.dict())

    logger.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ {file.filename} –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")

    return OCRResponse(
        model_path=model_path,
        filename=file.filename,
        lines=ocr_lines,
        total_lines=qnty_lines,
        status="success"
    )


if __name__ == "__main__":
    import sys
    import asyncio
    from pathlib import Path


    # –ü—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ UploadFile
    class SimpleFile:
        def __init__(self, filepath):
            self.filename = Path(filepath).name
            self.filepath = filepath

        async def read(self):
            with open(self.filepath, 'rb') as f:
                return f.read()


    async def main():

        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: <–ø—É—Ç—å_–∫_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é> [–ø—É—Ç—å_–∫_–º–æ–¥–µ–ª–∏] [—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ]")

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        image_path = r'D:\DOC\2025-11-trocr_train\datasets\IMG_20191129_125404.jpg'

        # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∞—à–∞ –æ–±—É—á–µ–Ω–Ω–∞—è)
        model_path = r'D:\DOC\2025-11-trocr_train\output\2025-12-24_21-57\best_cer_model'

        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device = "cuda" if torch.cuda.is_available() else "cpu"

        print(f"üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        print(f"ü§ñ –ú–æ–¥–µ–ª—å: {model_path}")
        print(f"‚öôÔ∏è  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        print("-" * 50)

        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Ñ–∞–π–ª–∞ –∏ –≤—ã–∑—ã–≤–∞–µ–º –≤–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é
        file_obj = SimpleFile(image_path)
        result = await ocr_image(file_obj, model_path, device)

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print("\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø:")
        print("=" * 50)

        # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if hasattr(result, 'lines'):  # –ï—Å–ª–∏ —ç—Ç–æ OCRResponse
            for line in result.lines:
                print(f"–°—Ç—Ä–æ–∫–∞ {line.get('line_number', '?')}: {line.get('text', '')}")
        elif isinstance(result, dict) and 'lines' in result:
            for line in result['lines']:
                print(f"–°—Ç—Ä–æ–∫–∞ {line.get('line_number', '?')}: {line.get('text', '')}")
        else:
            print(result)


    # –ó–∞–ø—É—Å–∫–∞–µ–º
    asyncio.run(main())