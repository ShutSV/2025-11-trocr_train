

import io, re, gc, torch, logging, json
from torch.nn.utils.rnn import pad_sequence
import webdataset as wds
from PIL import Image
from pathlib import Path
from jiwer import cer, wer
from transformers import (VisionEncoderDecoderModel, TrOCRProcessor, TrainingArguments, Trainer, TrainerCallback)
from peft import (LoraConfig, get_peft_model, TaskType,)
from datetime import datetime

# =============================
# CONFIG
# =============================
MODEL_PATH = "input/trocr_cyr_ready"
PROCESSOR_PATH = "input/trocr_cyr_processor"
DATASET_DIR = Path(r"D:\datasets\rus\datasets\wds_format")
TRAIN_SHARDS = str(DATASET_DIR / "train-{000000..000044}.tar")
VAL_SHARDS   = str(DATASET_DIR / "val-{000000..000003}.tar")
TIMESTAMP = datetime.now().strftime('%Y-%m-%d_%H-%M')
OUTPUT_DIR = Path(rf"D:\DOC\2025-11-trocr_train\trocr_cyr_lora\{TIMESTAMP}")
LOG_DIR = Path(rf"{OUTPUT_DIR}\logs")

MAX_LEN = 128
BATCH_SIZE = 64
# GRAD_ACCUM = 4
LR = 1e-4
MAX_STEPS = 300_000
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# =============================
# –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
# =============================
def setup_logging():
    LOG_DIR.mkdir(exist_ok=True)  # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = LOG_DIR / f"training_{timestamp}.log"
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', handlers=[logging.FileHandler(log_file), logging.StreamHandler()])
    return log_file

# =============================
# TEXT NORMALIZATION
# =============================
def normalize_text(text: str) -> str:
    # text = text.lower()
    text = text.replace("—ë", "–µ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()

# =============================
# DATASET TRANSFORM
# =============================
class TrOCRTransform:
    def __init__(self, processor, max_len=128):
        self.processor = processor
        self.max_len = max_len

    def __call__(self, sample):
        if sample is None:
            return None
        img_raw, text = sample
        try:
            if isinstance(img_raw, bytes):
                image = Image.open(io.BytesIO(img_raw)).convert("RGB")
            else:
                image = img_raw.convert("RGB")
            pixel_values = self.processor(images=image, return_tensors="pt").pixel_values[0]
            enc = self.processor.tokenizer(text, padding="max_length", truncation=True, max_length=self.max_len,)
            labels = [t if t != self.processor.tokenizer.pad_token_id else -100 for t in enc.input_ids]
            return {"pixel_values": pixel_values, "labels": torch.tensor(labels, dtype=torch.long),}
        except Exception:
            return None

def filter_none(x):
    return x is not None

def get_wds_dataset(shards, processor, max_len=128, shuffle=True):
    fixed = "file:" + shards.replace("\\", "/")
    transform = TrOCRTransform(processor, max_len)
    dataset = wds.WebDataset(fixed, shardshuffle=100 if shuffle else 0)
    if shuffle:
        dataset = dataset.shuffle(1_500_000)
    dataset = (dataset.decode().to_tuple("png", "txt").map(transform, handler=wds.warn_and_continue).select(filter_none))
    return dataset

# =======================
# DataLoader collate_fn
# =======================
def collate_fn_trOCR(batch):
    pixel_values = torch.stack([item["pixel_values"] for item in batch])
    labels = pad_sequence([item["labels"] for item in batch], batch_first=True, padding_value=-100)
    return {"pixel_values": pixel_values, "labels": labels}

# =============================
# –ö–ê–°–¢–û–ú–ù–´–ô CALLBACK –î–õ–Ø –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
# =============================
class DetailedValidationLogger(TrainerCallback):
    def __init__(self, processor):
        self.processor = processor
        self.validation_logs = []
        self.best_cer = float('inf')

    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        if metrics:
            # –õ–æ–≥–∏—Ä—É–µ–º –≤ –∫–æ–Ω—Å–æ–ª—å —Å –¥–µ—Ç–∞–ª—è–º–∏
            logging.info("=" * 80)
            logging.info(f"VALIDATION - Step {state.global_step}")
            logging.info("-" * 80)
            for key, value in metrics.items():
                logging.info(f"{key}: {value:.6f}")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self.validation_logs.append({"step": state.global_step, "metrics": metrics, "timestamp": datetime.now().isoformat()})
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON —Ñ–∞–π–ª
            with open("validation_metrics.json", "w") as f:
                json.dump(self.validation_logs, f, indent=2)
            # –õ–æ–≥–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–∏–µ CER
            if "eval_cer" in metrics and metrics["eval_cer"] < self.best_cer:
                self.best_cer = metrics["eval_cer"]
                logging.info(f"üéâ {datetime.now().strftime('%Y-%m-%d_%H-%M')} NEW BEST CER: {self.best_cer:.6f} (improvement)")
                best_model_dir = Path(rf"{OUTPUT_DIR}\best_cer_model_cer-{self.best_cer}")
                best_model_dir.mkdir(parents=True, exist_ok=True)
                self.processor.save_pretrained(best_model_dir)
                logging.info(f"üéâ {datetime.now().strftime('%Y-%m-%d_%H-%M')} –ª—É—á—à–∞—è –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {best_model_dir}")

            logging.info("=" * 80)

# =============================
# –ö–ê–°–¢–û–ú–ù–´–ô CALLBACK –î–õ–Ø –û–ß–ò–°–¢–ö–ò –í–ò–î–ï–û–ü–ê–ú–Ø–¢–ò
# =============================
class SmartMemoryCallback(TrainerCallback):
    def __init__(self, memory_threshold_gb=0.5):
        self.memory_threshold = memory_threshold_gb * 1024 ** 3  # –ü–æ—Ä–æ–≥ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤ –±–∞–π—Ç–∞—Ö
        self.last_memory = 0

    def on_log(self, args, state, control, logs=None, **kwargs):
        if not torch.cuda.is_available():
            return
        current_memory = torch.cuda.memory_allocated()
        if current_memory - self.last_memory > self.memory_threshold:
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            if logs is not None:
                logs["memory_cleaned"] = True
                logs["memory_before_cleanup_gb"] = current_memory / 1024 ** 3
            self.last_memory = torch.cuda.memory_allocated()

    def on_evaluate_end(self, args, state, control, **kwargs):
        if torch.cuda.is_available():
            gc.collect()
            torch.cuda.empty_cache()

# =============================
# LOAD PROCESSOR & MODEL
# =============================
processor = TrOCRProcessor.from_pretrained(PROCESSOR_PATH, use_fast=False)
model = VisionEncoderDecoderModel.from_pretrained(MODEL_PATH)
model.to(DEVICE)

# =============================
# LORA
# =============================
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type=TaskType.CAUSAL_LM,
    target_modules=["q_proj", "v_proj"],
)
model.decoder = get_peft_model(model.decoder, lora_config)
for p in model.encoder.parameters():
    p.requires_grad = False
model.decoder.print_trainable_parameters()

# =============================
# DATASETS
# =============================
train_dataset = get_wds_dataset(TRAIN_SHARDS, processor, MAX_LEN, shuffle=True,)
val_dataset = get_wds_dataset(VAL_SHARDS, processor, MAX_LEN,shuffle=False,)

# =============================
# METRICS
# =============================
def decode_predictions(pred_ids):
    texts = processor.batch_decode(pred_ids, skip_special_tokens=True,)
    return [normalize_text(t) for t in texts]

def decode_labels(labels):
    labels = labels.clone()
    labels[labels == -100] = processor.tokenizer.pad_token_id
    texts = processor.batch_decode(labels, skip_special_tokens=True,)
    return [normalize_text(t) for t in texts]

def compute_metrics(pred):
    labels_ids = pred.label_ids
    pred_ids = pred.predictions
    pred_str = decode_predictions(pred_ids)
    label_str = decode_labels(labels_ids)
    #
    print(f"\n–ü—Ä–∏–º–µ—Ä—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (CER: {cer:.4f}):")  # –ü—Ä–æ—Å—Ç–æ –ø–µ—á–∞—Ç–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å—Ä–∞–∑—É –∑–¥–µ—Å—å
    for i in range(min(3, len(pred_str))):
        print(f"  True: '{label_str[i]}'")
        print(f"  Pred: '{pred_str[i]}'")
        print()
    # return {"cer": cer(label_str, pred_str), "wer": wer(label_str, pred_str)}

    metrics = {"cer": cer(label_str, pred_str), "wer": wer(label_str, pred_str)}  # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    total_chars = sum(len(text) for text in label_str)  # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_words = sum(len(text.split()) for text in label_str)
    metrics.update({"total_samples": len(label_str), "avg_chars_per_sample": total_chars / len(label_str), "avg_words_per_sample": total_words / len(label_str),})
    if len(pred_str) > 0:  # –õ–æ–≥–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ (–ø–µ—Ä–≤—ã–µ 3)
        logging.info("Validation samples:")
        for i in range(min(3, len(pred_str))):
            logging.info(f"  Sample {i}:")
            logging.info(f"    True:  {label_str[i]}")
            logging.info(f"    Pred:  {pred_str[i]}")
            logging.info(f"    Match: {label_str[i] == pred_str[i]}")
    return metrics


if __name__ == "__main__":

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_file = setup_logging()
    logging.info(f"Training started. Logs will be saved to: {log_file}")

    # =============================
    # TRAINING ARGS
    # =============================
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        per_device_train_batch_size=BATCH_SIZE,
        per_device_eval_batch_size=BATCH_SIZE,
        # gradient_accumulation_steps=GRAD_ACCUM,
        learning_rate=LR,
        # warmup_steps=10_000,
        warmup_steps=200,
        # max_steps=MAX_STEPS,
        max_steps=2_000,
        fp16=True,

        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging_strategy="steps",
        logging_steps=50,
        logging_dir="./logs/tensorboard",

        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        eval_strategy="steps",
        # eval_steps=20_000,
        eval_steps=300,

        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_strategy="steps",
        # save_steps=20_000,
        save_steps=300,
        save_total_limit=3,

        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        log_level="info",
        log_level_replica="warning",
        logging_first_step=True,  # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π —à–∞–≥
        logging_nan_inf_filter=False,  # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è
        disable_tqdm=False,  # –í–∏–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä

        # –û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å
        report_to="tensorboard",

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        load_best_model_at_end=True,
        metric_for_best_model="cer",
        greater_is_better=False,

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        remove_unused_columns=False,
        eval_accumulation_steps=1,  # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ—Ü–µ–Ω–∫–∏
        dataloader_pin_memory=torch.cuda.is_available(),  # –£—Å–∫–æ—Ä–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        dataloader_num_workers=4,
        dataloader_prefetch_factor=64,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π, –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö –∫–∞–∂–¥—ã–º worker'–æ–º –∑–∞—Ä–∞–Ω–µ–µ - –û–¢–ö–õ–Æ–ß–ò–¢–¨ –¥–ª—è [i9 185H]
    )

    # =============================
    # TRAINER
    # =============================
    validation_logger = DetailedValidationLogger(processor)  # –°–æ–∑–¥–∞–µ–º callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    memory_callback = SmartMemoryCallback()

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=collate_fn_trOCR,
        tokenizer=None,
        compute_metrics=compute_metrics,
        callbacks=[validation_logger, memory_callback],
    )
    # =============================
    # TRAIN
    # =============================
    logging.info("Starting training...")
    trainer.train()

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    logging.info("Running final evaluation...")
    final_metrics = trainer.evaluate()
    logging.info(f"Final metrics: {final_metrics}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    FINAL_PATH = Path(rf"{OUTPUT_DIR}\final")
    FINAL_PATH.mkdir(parents=True, exist_ok=True)
    trainer.save_model(str(FINAL_PATH))
    processor.save_pretrained(str(FINAL_PATH))
    logging.info(f"üéâ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {str(FINAL_PATH)}. Training completed!")
